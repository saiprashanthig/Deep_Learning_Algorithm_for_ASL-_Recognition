# A Deep Learning-Based Algorithm for American Sign Language Recognition

This is the final project for the course Mathematical Techniques in Data Science (MATH 637) at the University of Delaware. The course instructor is Dr. Vu Dinh.

ABSTRACT 

This project aims at developing a robust Convolutional Neural Network (CNN) for the efficient categorization of American Sign Language (ASL) signs. The primary dataset for this project is sourced from Kaggle and comprises 2,515 high-resolution images. These images represent 36 distinct classes, including the digits 0-9 and the letters A-Z as expressed in ASL.

The project plans to leverage the power of deep learning tools such as Keras, TensorFlow, and Python to train a CNN model capable of multi-class image classification. Initially, we will develop a prototype CNN model to assess the overall accuracy of the dataset. The process involves several stages, including data preprocessing, model development, hyperparameter tuning, model evaluation, and prediction. 

To enhance the practicality of the dataset and improve the modelâ€™s predictive capabilities, we plan to explore various data augmentation techniques. These may include rotating images within a range of -45 to 45 degrees and experimenting with zooming in or out on existing sign images. In We plan to include our own images depicting ASL signs. This will not only enrich our dataset but also ensure that our model is trained on a diverse set of images, thereby increasing its generalization capabilities.The goal of this project is to bridge the communication gap between speech-impaired individuals and the general population and create a more inclusive society. 






